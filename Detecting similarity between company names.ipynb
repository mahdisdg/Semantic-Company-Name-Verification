{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14015341,"sourceType":"datasetVersion","datasetId":8928524}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **Cell 1: Environment Setup and Dependency Fixes**\n\nWhen I started running the notebook, I encountered a binary incompatibility error because the latest version of Numpy (2.0+) conflicts with the current Transformers library. To fix this, I force-installed a legacy version of Numpy (<2.0). I also installed `dadmatools` for Persian text normalization and `sentence-transformers` for the vector embedding tasks.","metadata":{}},{"cell_type":"code","source":"!pip uninstall -y transformers sentence-transformers numpy\n!pip install -U \"sentence-transformers>=3.0.0\" transformers \"numpy<2.0\" dadmatools python-Levenshtein pandas","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Cell 2: Importing Libraries and GPU Check**\n\nHere, I am importing the necessary libraries. I'm using `pandas` for data handling and `torch` to manage the computation device. I included a check to ensure the code detects the GPU (CUDA); otherwise, generating embeddings for 10,000 rows would take too long on the CPU.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport Levenshtein\nfrom dadmatools.normalizer import Normalizer\nfrom sentence_transformers import SentenceTransformer\n\n# checking if cuda is available to speed up the embedding process\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Running on: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T20:01:38.095139Z","iopub.execute_input":"2025-12-05T20:01:38.095722Z","iopub.status.idle":"2025-12-05T20:01:38.100727Z","shell.execute_reply.started":"2025-12-05T20:01:38.095694Z","shell.execute_reply":"2025-12-05T20:01:38.099824Z"}},"outputs":[{"name":"stdout","text":"Running on: cuda\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"### **Cell 3: Building the Root-Word Dictionary**\n\nTo handle Rule 5 (Singular/Plural and Root variations), I cannot rely solely on the model. I used the provided `dataset_sample.csv` to build a lookup dictionary. I iterate through the file, and wherever the validation column confirms a relationship (e.g., \"valid\" or \"duplicate\"), I map the derivative word to its root (Lemma). This allows me to normalize words like \"تاجر\" to \"تجارت\" before processing.","metadata":{}},{"cell_type":"code","source":"# loading the dataset that contains root and derivative pairs\ntry:\n    lemma_df = pd.read_csv('/kaggle/input/mydatasets/dataset_sample.csv')\n    \n    lemma_dict = {}\n    # these markers in the csv indicate that the words are related\n    valid_markers = ['بله', 'تکراری', 'بله.', 'بله ']\n\n    for index, row in lemma_df.iterrows():\n        status = str(row['valid']).strip()\n        \n        # if the relationship is valid, add it to the dictionary\n        if status in valid_markers:\n            root = str(row['lem']).strip()\n            word = str(row['derivitive']).strip()\n            lemma_dict[word] = root\n            \n    print(f\"Dictionary built. Contains {len(lemma_dict)} root mappings.\")\n    \nexcept FileNotFoundError:\n    print(\"Error: dataset_sample.csv not found. please check the path.\")\n    lemma_dict = {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T20:08:22.269183Z","iopub.execute_input":"2025-12-05T20:08:22.269525Z","iopub.status.idle":"2025-12-05T20:08:22.320714Z","shell.execute_reply.started":"2025-12-05T20:08:22.269500Z","shell.execute_reply":"2025-12-05T20:08:22.319960Z"}},"outputs":[{"name":"stdout","text":"Dictionary built. Contains 820 root mappings.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### **Cell 4: The Preprocessing Pipeline**\n\nI defined a `preprocess` function that acts as the backbone of this system. It performs four steps:\n1. Normalizes Persian characters (e.g., unifying 'ک' and 'ی') using `dadmatools`.\n2. Tokenizes the string.\n3. Removes \"Stop Words\" (generic legal terms like \"شرکت\", \"موسسه\", \"مهندسی\") because they create noise in similarity searches.\n4. Lemmatizes the tokens using the dictionary created in the previous step.\nThis ensures that \"Mihan Food Company\" and \"Mihan Foods\" result in the exact same processed string.","metadata":{}},{"cell_type":"code","source":"# initializing the dadmatools normalizer with standard settings\nnormalizer = Normalizer(\n    full_cleaning=False,\n    unify_chars=True,\n    refine_punc_spacing=True,\n    remove_extra_space=True\n)\n\n# list of generic words that don't add semantic value to the name\n# removing these helps avoid false positives\nSTOPWORDS = {\n    \"شرکت\", \"موسسه\", \"سهامی\", \"خاص\", \"عام\", \"مسئولیت\", \"محدود\",\n    \"تعاونی\", \"گروه\", \"صنایع\", \"مجتمع\", \"کارخانجات\", \"تولیدی\", \"بازرگانی\",\n    \"خدماتی\", \"مهندسی\", \"پخش\", \"توزیع\", \"و\", \"در\", \"به\", \"های\", \"ای\"\n}\n\ndef preprocess(text):\n    if not isinstance(text, str):\n        return None\n        \n    # step 1: normalize characters\n    text = normalizer.normalize(text)\n    \n    # step 2: split and remove stopwords\n    tokens = text.split()\n    clean_tokens = [t for t in tokens if t not in STOPWORDS]\n    \n    if not clean_tokens:\n        return None\n\n    # step 3: convert words to their roots using the dictionary\n    lemma_tokens = [lemma_dict.get(t, t) for t in clean_tokens]\n    \n    # returning a dict with different formats for different checks\n    return {\n        \"original\": text,\n        \"clean_tokens\": set(clean_tokens),        # set is faster for subset checks\n        \"clean_string\": \" \".join(clean_tokens),   # string for levensthein distance\n        \"lemma_string\": \" \".join(lemma_tokens)    # lemmatized string for embedding\n    }\n\nprint(\"Preprocessing pipeline ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T20:10:45.224248Z","iopub.execute_input":"2025-12-05T20:10:45.224598Z","iopub.status.idle":"2025-12-05T20:10:45.232792Z","shell.execute_reply.started":"2025-12-05T20:10:45.224570Z","shell.execute_reply":"2025-12-05T20:10:45.231975Z"}},"outputs":[{"name":"stdout","text":"Preprocessing pipeline ready.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"### **Cell 5: Indexing the Database**\n\nIn this step, I loaded the 10,000 registered company names. I applied the preprocessing pipeline to all of them. Then, I used the `intfloat/multilingual-e5-large` model to convert the lemmatized names into vectors. I chose E5 over ParsBERT because E5 is optimized for retrieval tasks. I added the \"passage: \" prefix to the text because this specific model requires it to distinguish between the documents being indexed and the query.\n","metadata":{}},{"cell_type":"code","source":"# loading the main data\ndf = pd.read_csv('/kaggle/input/mydatasets/data_sample.csv')\n\n# preprocessing all 10k rows\nprint(\"Preprocessing 10,000 rows...\")\nprocessed_data = df['name'].apply(preprocess).tolist()\n\n# filtering out any rows that became empty after stopword removal\nvalid_indices = [i for i, x in enumerate(processed_data) if x is not None]\ndf = df.iloc[valid_indices].reset_index(drop=True)\nprocessed_list = [processed_data[i] for i in valid_indices]\n\n# saving the processed forms back to the dataframe\ndf['clean_tokens'] = [x['clean_tokens'] for x in processed_list]\ndf['clean_string'] = [x['clean_string'] for x in processed_list]\ndf['lemma_string'] = [x['lemma_string'] for x in processed_list]\n\n# generating embeddings\nprint(\"Generating embeddings using GPU...\")\nmodel = SentenceTransformer('intfloat/multilingual-e5-large', device=device)\n\n# e5 models expect 'passage: ' prefix for the documents in the index\ndocs_to_encode = [\"passage: \" + x for x in df['lemma_string']]\n\n# encoding in batches to manage memory\ndb_vectors = model.encode(\n    docs_to_encode,\n    batch_size=32,\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    normalize_embeddings=True \n)\n\nprint(f\"Database indexed. Matrix shape: {db_vectors.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T20:11:35.671682Z","iopub.execute_input":"2025-12-05T20:11:35.672272Z","iopub.status.idle":"2025-12-05T20:11:58.823964Z","shell.execute_reply.started":"2025-12-05T20:11:35.672248Z","shell.execute_reply":"2025-12-05T20:11:58.823148Z"}},"outputs":[{"name":"stdout","text":"Preprocessing 10,000 rows...\nGenerating embeddings using GPU...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/313 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f592520f5110436b9ce566a0138e7bd9"}},"metadata":{}},{"name":"stdout","text":"Database indexed. Matrix shape: (10000, 1024)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"### **Cell 6: The Validation Logic (Rules 1-6)**\n\nThis is the core logic function. It takes a new name, preprocesses it, and converts it to a vector query (prefixed with \"query: \"). I calculate the cosine similarity against the database and select the top 15 candidates.\nI then iterate through these candidates applying the rules hierarchically specified in the task:\n1.  **Python Checks (Rules 1-3):** I use strict string comparison and set operations to catch exact matches, subsets, and permutations. These are 100% accurate.\n2.  **Levenshtein Distance (Rule 4):** I check for typos only if the vector similarity is reasonably high (> 0.7) to save computation.\n3.  **Semantic Similarity (Rule 5 & 6):** I rely on the embedding score. If the score exceeds 0.88, I flag it as a semantic conflict.","metadata":{}},{"cell_type":"code","source":"def check_name_rules(new_name):\n    \"\"\"\n    Checks the 6 rules defined in the project requirements.\n    \"\"\"\n    # preprocessing the input\n    input_data = preprocess(new_name)\n    if not input_data:\n        return \"Invalid input (empty or only stopwords)\"\n        \n    input_clean_str = input_data['clean_string']\n    input_tokens = input_data['clean_tokens']\n    input_lemma_str = input_data['lemma_string']\n    \n    print(f\"Checking: {new_name}\")\n    print(f\"Processed: {input_clean_str}\")\n    print(f\"Roots: {input_lemma_str}\")\n    \n    # vector search\n    # e5 models expect 'query: ' prefix for the search query\n    query_vec = model.encode([\"query: \" + input_lemma_str], normalize_embeddings=True)\n    \n    # calculating cosine similarity\n    scores = np.dot(db_vectors, query_vec.T).flatten()\n    \n    # getting top 15 candidates\n    top_indices = np.argsort(scores)[::-1][:15]\n    \n    for idx in top_indices:\n        score = scores[idx]\n        candidate_row = df.iloc[idx]\n        cand_name = candidate_row['name']\n        cand_clean_str = candidate_row['clean_string']\n        cand_tokens = candidate_row['clean_tokens']\n        \n        # rule 1: exact match check\n        if input_clean_str == cand_clean_str:\n            return f\"REJECTED | Conflict: {cand_name} | Reason: Rule 1 (Exact Match)\"\n\n        # rule 2: subset check (input inside existing or existing inside input)\n        if input_tokens.issubset(cand_tokens):\n            return f\"REJECTED | Conflict: {cand_name} | Reason: Rule 2 (Input is a subset)\"\n        if cand_tokens.issubset(input_tokens):\n            return f\"REJECTED | Conflict: {cand_name} | Reason: Rule 2 (Existing name is a subset)\"\n\n        # rule 3: permutation check (same words, different order)\n        if input_tokens == cand_tokens:\n             return f\"REJECTED | Conflict: {cand_name} | Reason: Rule 3 (Word Permutation)\"\n\n        # rule 4: typos / levenshtein distance\n        # only checking this if the vector score is high enough to suggest similarity\n        if score > 0.7:\n            edit_dist = Levenshtein.distance(input_clean_str, cand_clean_str)\n            # stricter threshold for short names\n            threshold = 1 if len(input_clean_str) < 5 else 2\n            if edit_dist <= threshold:\n                return f\"REJECTED | Conflict: {cand_name} | Reason: Rule 4 (Typo/Spelling too similar)\"\n\n        # rule 5 & 6: semantic / roots\n        # using the embedding score to catch semantic issues\n        if score >= 0.88:\n            return f\"REJECTED | Conflict: {cand_name} | Reason: Rule 5/6 (High Semantic Similarity: {score:.3f})\"\n\n    return \"ACCEPTED | Name appears valid.\"\n\nprint(\"Validation logic ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T20:13:02.624815Z","iopub.execute_input":"2025-12-05T20:13:02.625090Z","iopub.status.idle":"2025-12-05T20:13:02.632634Z","shell.execute_reply.started":"2025-12-05T20:13:02.625069Z","shell.execute_reply":"2025-12-05T20:13:02.631837Z"}},"outputs":[{"name":"stdout","text":"Validation logic ready.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"### **Cell 7: Testing**\n\nFinally, I ran the system against some test cases to verify accuracy.","metadata":{}},{"cell_type":"code","source":"test_cases = [\n    \"عمران خطوط سورن\",\n    \"كالا پخش ايلام\",\n    \"غذایی صنایع میهن\",\n    \"صنایع غزایی میهن\",\n    \"صنعت غذا میهن\",\n    \"شرکت فولاد مبارکه اصفهان\",\n    \"شعبه اصفهان شرکت مهر افزون خرم آباد\",\n]\n\nprint(\"--- RUNNING TESTS ---\")\nfor name in test_cases:\n    result = check_name_rules(name)\n    print(result)\n    print(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T20:20:42.159306Z","iopub.execute_input":"2025-12-05T20:20:42.159921Z","iopub.status.idle":"2025-12-05T20:20:42.482080Z","shell.execute_reply.started":"2025-12-05T20:20:42.159895Z","shell.execute_reply":"2025-12-05T20:20:42.481001Z"}},"outputs":[{"name":"stdout","text":"--- RUNNING TESTS ---\nChecking: عمران خطوط سورن\nProcessed: عمران خطوط سورن\nRoots: عمران خطوط سورن\nREJECTED | Conflict: عمران خطوط سورن | Reason: Rule 1 (Exact Match)\n--------------------------------------------------\nChecking: كالا پخش ايلام\nProcessed: کالا ایلام\nRoots: کالا ایلام\nREJECTED | Conflict: كالا پخش عصر ايلام | Reason: Rule 2 (Input is a subset)\n--------------------------------------------------\nChecking: غذایی صنایع میهن\nProcessed: غذایی میهن\nRoots: غذایی میهن\nACCEPTED | Name appears valid.\n--------------------------------------------------\nChecking: صنایع غزایی میهن\nProcessed: غزایی میهن\nRoots: غزایی میهن\nACCEPTED | Name appears valid.\n--------------------------------------------------\nChecking: صنعت غذا میهن\nProcessed: صنعت غذا میهن\nRoots: صنعت غذا میهن\nACCEPTED | Name appears valid.\n--------------------------------------------------\nChecking: شرکت فولاد مبارکه اصفهان\nProcessed: فولاد مبارکه اصفهان\nRoots: فولاد مبارکه اصفهان\nACCEPTED | Name appears valid.\n--------------------------------------------------\nChecking: شعبه اصفهان شرکت مهر افزون خرم آباد\nProcessed: شعبه اصفهان مهر افزون خرم آباد\nRoots: شعبه اصفهان مهر افزون خرم آباد\nREJECTED | Conflict: شعبه تهران شرکت مهر افزون خرم آباد | Reason: Rule 5/6 (High Semantic Similarity: 0.890)\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"## Idea to improve accuracy:\n### After obtaining the closest names through embeddings, instead of relying on the cosine distance and the obtained score, we can input the candidate names and the user's desired name into an LLM configured with prompt engineering, and ask it to reject the user's request if it sees a similar name.","metadata":{}}]}